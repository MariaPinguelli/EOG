{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação dos dados EOG\n",
    "\n",
    "Neste notebook está incluído os seguintes passos:\n",
    "- Aplicação de características;\n",
    "- Criação do vetor de características;\n",
    "- Normalização de dados;\n",
    "- Seleção de características;\n",
    "- Classificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma característica é uma propriedade individual mensurável ou característica de um fenômeno que está sendo observado. Em nosso caso de EOG, uma característica pode ser extraída no domínio do tempo ou no domínio da frequência. As características a seguir foram retiradas do artigo *EMG Feature Extraction for Tolerance of White Gaussian Noise* \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP): \n",
    "\n",
    "    > $ \\sum_{i=1}^{N-1}f(|x_i - x_{i+1}|) $\n",
    "    \n",
    "    > $ f(x) = \\begin{cases} 1 & \\text{if } x \\gt threshold \\\\ 0 & \\text{otherwise} \\end{cases} $\n",
    "\n",
    "2. Variance of EMG (VAR)\n",
    "\n",
    "    > $ \\frac{1}{N-1}\\sum_{i=1}^{N}x_i^2 $\n",
    "\n",
    "3. Root Mean Square (RMS)\n",
    "\n",
    "    > $ \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}|x_i|^2} $\n",
    "\n",
    "4. Waveform Length (WL)\n",
    "    \n",
    "    > $ \\sum_{i=1}^{N-1}|x_{i+1} - x_i| $\n",
    "\n",
    "5. Zero Crossing (ZC)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N}sgn(x_i) $\n",
    "    \n",
    "    > $ sgn(x) = \\begin{cases} 1 & \\text{if } x_i * x_{i+1} \\leq 0 \\\\ 0 & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}PSD_j $\n",
    "\n",
    "2. Mean Frequency (FMN)\n",
    "\n",
    "    > $\\sum_{j=1}^{M}f_j PSD_j / \\sum_{j=1}^{M}PSD_j$\n",
    "    \n",
    "    > $ f_j = j * SampleRate / 2 * M $\n",
    "\n",
    "3. Modified Median Frequency (MMDF)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}A_j $\n",
    "    \n",
    "    > $ A_j = Amplitude\\ do\\ espectro\\ j $\n",
    "\n",
    "4. Modified Frequency Mean (MMNF)\n",
    "\n",
    "    > $ \\sum_{j=1}^{M}f_jAj / \\sum_{j=1}^{M}Aj $\n",
    "\n",
    "\n",
    "\\[1\\] Phinyomark, Angkoon & Limsakul, Chusak & Phukpattaranont, P.. (2008). EMG Feature Extraction for Tolerance of White Gaussian Noise.\n",
    "[Disponível neste link](https://www.researchgate.net/publication/263765853_EMG_Feature_Extraction_for_Tolerance_of_White_Gaussian_Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 1**: Descrever as características de acordo com o artigo citado e outros disponíveis relacionados. O que está querendo \"ser visto\" em cada característica? Qual é o significado matemático de cada uma delas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP): é o número de contagens para cada mudançais the number of counts for each change in the EMG signal\n",
    "amplitude that exceeds a predefined threshold where threshold value is 10 mV.\n",
    "\n",
    "2. Variance of EMG (VAR): expressa o poder do sinal EMG como caracteristica utilizavel.\n",
    "\n",
    "3. Root Mean Square (RMS): RMS representa caracteristicas no dominio do tempo baseado na amplitude do sinal como valor absoluto médio, inclinação média do valor absoluto, e variação.\n",
    "\n",
    "4. Waveform Length (WL): é o cumprimento cumulativo da onda durante o segmento de tempo. WL é relacionado a amplitude, frequência e tempo da onda.\n",
    "\n",
    "5. Zero Crossing (ZC): é o número de vezes que os sinais EMG passam de 0. O valor limit é 20 mV. Essas características fornecem uma estimativa aproximada das propriedades no dominio da frequência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD): é a frequência na qual o espectro é dividido em duas regiões com potências iguais.\n",
    "\n",
    "2. Mean Frequency (FMN): é a frequência média.\n",
    "\n",
    "3. Modified Median Frequency (MMDF): é bem similar ao método FMD, mas é baseado no espectro de amplitude, não no PSD.\n",
    "\n",
    "4. Modified Frequency Mean (MMNF): é a frequência média baseada no espectro da amplitude diferente do FMN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando as características\n",
    "\n",
    "É necessário implementar as características, geralmente em formato de funções ou métodos, para que seja possível aplicar tais funções aos dados de entrada e obter as características resultantes. A seguir temos a implementação das características `VAR` & `RMS` (domínio do tempo) e `FDM` & `MMDF` (domínio da frequência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.io import loadmat\n",
    "import mne\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def fj(w):\n",
    "    sample_rate = np.arange(1, w.shape[-1]+1) * 200\n",
    "    return sample_rate / 2 * w.shape[-1]\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "def wamp(time, threshold):\n",
    "    return np.sum(np.abs(np.diff(time)) > threshold, axis=-1)\n",
    "\n",
    "def var(time):\n",
    "    return np.sum(time ** 2, axis=-1) / (np.prod(time.shape) - 1)\n",
    "\n",
    "def rms(time):\n",
    "    return np.sqrt(np.sum(np.abs(time) ** 2, axis=-1) / (np.prod(time.shape) - 1))\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def zc(x):\n",
    "    return np.count_nonzero(np.diff(np.sign(x), axis=-1) != 0, axis=-1)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def fmn(w):\n",
    "    return np.sum(fj(w) * PSD(w)) / fmd(w)*2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def mmnf(w):\n",
    "    return np.sum(fj(w) * np.abs(w),  axis=-1) / mmdf(w)*2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 2**: Implemente todas as características apresentadas neste tutorial em formato de funções. Sinta-se livre também para buscar e implementar características além das apresentadas, citando as fontes de tais características.\n",
    "\n",
    "\n",
    "#### Vetor de características\n",
    "\n",
    "Ao final da implementação e seleção das características, deve ser escolhida as características e então teremos um vetor com todas elas implementadas.\n",
    "\n",
    "O vetor de características estará organizado da seguinte forma (exemplo p/ VAR, RMS, RDM e MMDF):\n",
    "\n",
    "| ID sample | VAR1 | RMS1 | FMD1 | MMDF1 | VAR2 | RMS2 | FMD2 | MMDF2 | Classe |\n",
    "|:---------:|:----:|:----:|:----:|:-----:|------|------|------|-------|:------:|\n",
    "|     1     |  v1  |  v1  |  v1  |   v1  | v1   | v1   | v1   | v1    |    0   |\n",
    "|     2     |  v2  |  v2  |  v2  |   v2  | v2   | v2   | v2   | v2    |    0   |\n",
    "|    ...    |  ... |  ... |  ... |  ...  | ...  | ...  | ...  | ...   |   ...  |\n",
    "|     N     |  vN  |  vN  |  vN  |   vN  | vN   | vN   | vN   | vN    |    7   |\n",
    "\n",
    "#### Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores orginais: (2, 33, 33) (2, 33, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33),\n",
       " (2, 33))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando dados do \"prepare.ipynb\"\n",
    "time = np.load(\"dataset/data_b_time.npy\")\n",
    "freq = np.load(\"dataset/data_b_freq.npy\")\n",
    "\n",
    "time = time[:,:,:33]\n",
    "print(\"Shape dos vetores orginais:\", time.shape, freq.shape)\n",
    "\n",
    "# aplicando características\n",
    "data_wamp = wamp(time, 1)\n",
    "data_var = var(time)\n",
    "data_rms = rms(time)\n",
    "data_wl = wl(time)\n",
    "data_zc = zc(time)\n",
    "\n",
    "data_fmd = fmd(freq)\n",
    "data_fmn = fmn(freq)\n",
    "data_mmdf = mmdf(freq)\n",
    "data_mmnf = mmnf(freq)\n",
    "\n",
    "data_wamp.shape, data_var.shape, data_rms.shape, data_wl.shape, data_zc.shape, data_fmd.shape, data_fmn.shape, data_mmdf.shape, data_mmnf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2, 33)\n",
      "(2, 33, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66, 9)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features = np.array([data_wamp, data_var, data_rms, data_wl, data_zc, data_fmd, data_fmn, data_mmdf, data_mmnf])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(1, 2, 0)\n",
    "print(features.shape)\n",
    "\n",
    "# Criar vetor de caracteristicas definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1],\n",
    "                            features.shape[2])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 3*: Realização da normalização dos dados utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 4*: Realização da seleção de características, utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando seleção de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do vetor de *labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "# criação do vetor de labels final\n",
    "labels = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 9)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando normalização\n",
    "data_final = StandardScaler().fit_transform(features)\n",
    "labels_final = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "data_final = MinMaxScaler().fit_transform(data_final)\n",
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 9)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_reshape = imputer.fit_transform(data_final)\n",
    "\n",
    "# Normalizando o X\n",
    "X_norm = MinMaxScaler().fit_transform(X_reshape)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), min_features_to_select=100, step=5, cv=skf, scoring='accuracy')\n",
    "X_full = rfe.fit_transform(X_norm[:56,:], labels_final)\n",
    "X_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 5*: Realização da classificação utilizando `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [44, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Maria Fernanda\\Desktop\\EOG\\validation.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Maria%20Fernanda/Desktop/EOG/validation.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# aplicando a classificação\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Maria%20Fernanda/Desktop/EOG/validation.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train_full, X_test_full, y_train_full, y_test_full \u001b[39m=\u001b[39m train_test_split(X_full, labels_final, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Maria%20Fernanda/Desktop/EOG/validation.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m svm \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlinear\u001b[39;49m\u001b[39m'\u001b[39;49m, C\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, probability\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mfit(X_train_full, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Maria%20Fernanda/Desktop/EOG/validation.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_full_pred \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(X_test_full)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Maria%20Fernanda/Desktop/EOG/validation.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (accuracy_score(y_test_full, y_full_pred) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Maria Fernanda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:192\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    190\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    196\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    197\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    205\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Maria Fernanda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Maria Fernanda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\Maria Fernanda\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [44, 0]"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, labels_final, test_size=0.2, random_state=0)\n",
    "\n",
    "svm = SVC(kernel='linear', C=10, probability=True).fit(X_train_full, y)\n",
    "y_full_pred = svm.predict(X_test_full)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (accuracy_score(y_test_full, y_full_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
